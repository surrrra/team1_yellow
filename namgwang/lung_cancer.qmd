---
title: "lung_cancer"
editor: visual
---

# 목표: 이항 로지스틱 회귀분석 binomial logistic regression analysis을 통해서 폐암 발병률 예측

### 데이터셋 소개

출처 : https://www.kaggle.com/datasets/mysarahmadbhat/lung-cancer 이 데이터는 웹사이트 폐암 예측 시스템에서 수집된 데이터

```{r}
# 자료 받아오기
df <- read.csv('survey_lung_cancer.csv', stringsAsFactors=T)
# str(df)
```

### 컬럼 설명

-   LUNG_CANCER는 종속변수, AGE만 수치형, 나머지 14 컬럼은 범주형
-   AGE컬럼과 LUNG_CANCER 컬럼에 대해서 이항 로지스틱 회귀분석을 진행하고,
-   나머지 14컬럼과 LUNG_CANCER 컬럼에 대해서 카이스퀘어 검정 진행
-   이후 검정을 통과한 컬럼들을 모두 합쳐서 이항 로지스틱 회귀분석 재시행

| 컬럼                  | 유형 | 설명               |
|-----------------------|------|--------------------|
| Gender                | 범주 | 성별               |
| Age                   | 수치 | 나이               |
| Smoking               | 범주 | 담배               |
| Yellow_fingers        | 범주 | 노란 손가락        |
| Anxiety               | 범주 | 불안               |
| Peer_pressure         | 범주 | 동료 압박          |
| chronic_disease       | 범주 | 만성 질환          |
| fatigue               | 범주 | 피로               |
| allergy               | 범주 | 알러지             |
| wheezing              | 범주 | 숨참               |
| alcohol               | 범주 | 술                 |
| coughing              | 범주 | 기침               |
| shortness_of_breath   | 범주 | 호흡곤란           |
| swallowing_difficulty | 범주 | 삼킴곤란           |
| chest_pain            | 범주 | 가슴통증           |
| Lung_cancer           | 범주 | 폐암 여부: yes, no |

```{r, fig.height=15}
df$LUNG_CANCER
# 데이터 분포 살펴보기
par(mfrow=c(4,4))
for (col in colnames(df))
  if (col == 'AGE') {
    barplot(table(df[[col]]), main=col, col='limegreen')
  } else {barplot(table(df[[col]]), main=col, col=c('steelblue', 'coral'))}
par(mfrow=c(1,1))
```

### 결측치 체크

```{r}
sum(is.na(df))
```

# 1. 로지스틱 회귀분석 실행(LUNG_CANCER \~ AGE)

```{r}
# df$LUNG_CANCER <- factor(ifelse(df$LUNG_CANCER == 'YES',1, 0), levels=c(1,0), labels=c('YES', 'NO'))

# 샘플 나누기
df.train <- df[c(T,F) ,]
df.test <- df[c(F,T) ,]

# 샘플 잘 나누어졌는지 분포 확인
prop.table(table(df$LUNG_CANCER))
prop.table(table(df.train$LUNG_CANCER))
prop.table(table(df.test$LUNG_CANCER))

# 로지스틱 회귀분석 진행
model <- glm(LUNG_CANCER~AGE , data =df.train, family=binomial(link='logit'))
summary(model)

```

예측

```{r}
# 혼동행렬 만들기
df.train$pred <- factor(ifelse(model$fitted.values > 0.5, 'Yes', 'No'))
df_tab <- table(df.train$LUNG_CANCER, df.train$pred, dnn=c('Actual', 'Predicted'))
df_tab
# 분류모델의 성능 평가 지표
TP <- df_tab[2,2]
TN <- df_tab[1,1]
FP <- df_tab[1,2]
FN <- df_tab[2,1]
accuracy <- (TP + TN)/(TP+TN+FP+FN)
precision <-TP / (TP+FP)
recall <- TP / (TP+FN)
F1.score <- 2* precision * recall / (precision+recall)
d1 <- c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)
d1

library(pROC)
roc(LUNG_CANCER ~ model$fitted.values, data=df.train, plot=T, main='ROC curve', col='tomato')

df.test$pred <- predict(model, newdata=df.test, type='response')
df.test$pred <- factor(df.test$pred > 0.5, levels=c(F,T), labels=c('NO', 'YES'))
tab <-table(df.test$LUNG_CANCER, df.test$pred, dnn=c('Actual', 'Predicted'))
tab
TP <- tab[2,2]
TN <- tab[1,1]
FP <- tab[1,2]
FN <- tab[2,1]
accuracy <- (TP + TN)/(TP+TN+FP+FN)
precision <-TP / (TP+FP)
recall <- TP / (TP+FN)
F1.score <- 2* precision * recall / (precision+recall)
d3 <- c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)
```

# 2. 중간결과

-   AUC : 0.6347\
-   accuracy: 0.870
-   precision: 0.870
-   recall: 1.000
-   F1.score: 0.931

# 3. 카이 스퀘어 검정

```{r, fig.height=15}
# mosaicplot으로 값 분포 확인
par(mfrow=c(4,4))
for (col in colnames(df[,c(-2,-16)])) {
  mosaicplot(table(df[[col]], df[["LUNG_CANCER"]]), main=paste(col, ' ', 'LUNG_CANCER'), col=c('skyblue', 'tomato'))
}
par(mfrow=c(1,1))
```

```{r}
# 독립성 검정 수행
# 형 변환
dg <- df

for (n in c(1,3:15)) {
  dg[[colnames(dg)[n]]] <- factor(dg[[colnames(dg)[n]]])
}
str(dg)


chisq.test(df$GENDER, df$LUNG_CANCER)  # 0.3122
# chisq.test(df$YELLOW_FINGERS, df$LUNG_CANCER) # 0.0025
# chisq.test(df$SMOKING, df$LUNG_CANCER) # 0.3953
# chisq.test(df$ANXIETY, df$LUNG_CANCER) # 0.0174
# chisq.test(df$PEER_PRESSURE, df$LUNG_CANCER)  # 0.0019
# chisq.test(df$CHRONIC.DISEASE, df$LUNG_CANCER) # 0.0754
# chisq.test(df$FATIGUE, df$LUNG_CANCER)  # 0.01366
# chisq.test(df$ALLERGY, df$LUNG_CANCER)  # 2.281 * e^-8
# chisq.test(df$WHEEZING, df$LUNG_CANCER)  # 2.555 * e^-5
# chisq.test(df$ALCOHOL.CONSUMING, df$LUNG_CANCER)  # 9.607 * e^-7
# chisq.test(df$COUGHING, df$LUNG_CANCER)  # 2.717 * e^-5
# chisq.test(df$SHORTNESS.OF.BREATH, df$LUNG_CANCER)  # 0.3739
# chisq.test(df$SWALLOWING.DIFFICULTY, df$LUNG_CANCER) # 1.113 * e^-5
# chisq.test(df$CHEST.PAIN, df$LUNG_CANCER) # 0.0014
```

p-test 통과한 컬럼: YELLOW_FINGERS, ANXIETY, PEER_PRESSURE, FATIGUE, ALLERGY, WHEEZING, ALCOHOL.CONSUMING, COUGHING, SWALLOWING.DIFFICULTY, CHEST.PAIN

# 4. 로지스틱 회귀분석 실행(LUNG_CANCER \~ 컬럼 11개)

```{r}
# df$LUNG_CANCER <- factor(ifelse(df$LUNG_CANCER == 'YES',1, 0), levels=c(1,0), labels=c('YES', 'NO'))

# 샘플 나누기
dg.train <- dg[c(T,F) ,]
dg.test <- dg[c(F,T) ,]


# 샘플 잘 나누어졌는지 분포 확인
prop.table(table(dg$LUNG_CANCER))
prop.table(table(dg.train$LUNG_CANCER))
prop.table(table(dg.test$LUNG_CANCER))

# 로지스틱 회귀분석 진행
model <- glm(LUNG_CANCER~AGE+YELLOW_FINGERS+ANXIETY+PEER_PRESSURE+FATIGUE+ALLERGY+WHEEZING+ALCOHOL.CONSUMING+COUGHING+SWALLOWING.DIFFICULTY+CHEST.PAIN, data =dg.train, family=binomial(link='logit'))
summary(model)
```

```{r}
dg.train$pred <- factor(ifelse(model$fitted.values > 0.5, 'Yes', 'No'))

dg_tab <- table(dg.train$LUNG_CANCER, dg.train$pred, dnn = c('Actual', 'Predicted'))
dg_tab
# 분류모델의 성능 평가 지표 
TP <- dg_tab[2,2]
TN <- dg_tab[1,1]
FP <- dg_tab[1,2]
FN <- dg_tab[2,1]
accuracy <- (TP + TN)/(TP+TN+FP+FN)
precision <-TP / (TP+FP)
recall <- TP / (TP+FN)
F1.score <- 2* precision * recall / (precision+recall)
d2 <- c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)
d2
```

```{r}
```

```{r}
# AUC 구하기 
library(pROC)
roc(LUNG_CANCER ~ model$fitted.values, data=dg.train, plot=T, main='ROC curve', col='tomato')

# test셋에서 예측 적용
dg.test$pred <- predict(model, newdata=dg.test, type='response')
dg.test$pred <- factor(dg.test$pred > 0.5, levels=c(F,T), labels=c('NO', 'YES'))
dg_tab2 <-table(dg.test$LUNG_CANCER, dg.test$pred, dnn=c('Actual', 'Predicted'))
dg_tab2
TP <- dg_tab2[2,2]
TN <- dg_tab2[1,1]
FP <- dg_tab2[1,2]
FN <- dg_tab2[2,1]
accuracy <- (TP + TN)/(TP+TN+FP+FN)
precision <-TP / (TP+FP)
recall <- TP / (TP+FN)
F1.score <- 2* precision * recall / (precision+recall)
d4 <- c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)

rbind(전 = d1,후 = d2)
rbind(전 = d3,후 = d4)
```

```{r}

```

# 5. 결과

| 전-train | No  | Yes |
|----------|-----|-----|
| No       | 1   | 18  |
| Yes      | 0   | 136 |

| 전-test | No  | Yes |
|---------|-----|-----|
| No      | 0   | 20  |
| Yes     | 0   | 134 |

| 후-train | No  | Yes |
|----------|-----|-----|
| No       | 14  | 5   |
| Yes      | 4   | 132 |

| 후-test | No  | Yes |
|---------|-----|-----|
| No      | 11  | 9   |
| Yes     | 6   | 128 |

| 비교     | accuracy | precision | recall | F1.score |
|----------|----------|-----------|--------|----------|
| 전-train | 0.884    | 0.883     | 1.000  | 0.938    |
| 후-train | 0.942    | 0.964     | 0.971  | 0.967    |
| 전-test  | 0.870    | 0.870     | 1.000  | 0.931    |
| 후-test  | 0.903    | 0.934     | 0.955  | 0.945    |

-   train 비교
    -   정확도CA 0.06 증가, F1.score 0.03 증가
-   test 비교
    -   정확도CA 0.03 증가, F1.score 0.01 증가

결론 - 이항로지스틱 회귀분석을 사용하니 F1.score 0.94라는 높은 점수를 얻을 수 있었다.

### 기타

-   step 함수 써서 로지스틱 회귀분석

```{r}
# model2 <- step(model)
# summary(model2)
# 
# model2$fitted.values
# dg.train$pred2 <- factor(ifelse(model2$fitted.values > 0.5, 'Yes', 'No'))
# 
# dg.train$pred2
# table(dg.train$LUNG_CANCER, dg.train$pred2)
# 
# dg_tab <- table(dg.train$LUNG_CANCER, dg.train$pred2)
# dg_tab
# TP <- dg_tab[1,1]
# TN <- dg_tab[2,2]
# FP <- dg_tab[2,1]
# FN <- dg_tab[1,2]
# accuracy <- (TP + TN)/(TP+TN+FP+FN)
# precision <-TP / (TP+FP)
# recall <- TP / (TP+FN)
# F1.score <- 2* precision * recall / (precision+recall)
# d3 <- c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)
# rbind(d1,d2,d3)
```

-   페널티 로지스틱 회귀분석

```{r}
# 페널티 로지스틱 회귀분석
# x <- model.matrix(LUNG_CANCER~AGE+YELLOW_FINGERS+ANXIETY+PEER_PRESSURE+FATIGUE+ALLERGY+WHEEZING+ALCOHOL.CONSUMING+COUGHING+SWALLOWING.DIFFICULTY+CHEST.PAIN, dg.train)
# dg.train$LUNG_CANCER
# y <- ifelse(dg.train$LUNG_CANCER =='YES',1,0 )
# 
# library(glmnet)
# set.seed(123)
# model.cv <- cv.glmnet(x=x,y=y, family='binomial', alpha=0)
# model.pen <- glmnet(x,y, family='binomial', alpha=0, lambda=model.cv$lambda.min)
# model.test.x <- model.matrix(LUNG_CANCER~AGE+YELLOW_FINGERS+ANXIETY+PEER_PRESSURE+FATIGUE+ALLERGY+WHEEZING+ALCOHOL.CONSUMING+COUGHING+SWALLOWING.DIFFICULTY+CHEST.PAIN, dg.test)
# model.pred <- predict(model.pen, newx=model.test.x, type='response')
# model.pred <- ifelse(model.pred > 0.5, 'Yes', 'No')
# tab2 <- table(dg.test$LUNG_CANCER, model.pred, dnn=c('Actual', 'Predicted'))
# 
# TP <- tab2[2,2]
# TN <- tab2[1,1]
# FP <- tab2[2,1]
# FN <- tab2[1,2]
# accuracy <- (TP + TN)/(TP+TN+FP+FN)
# precision <-TP / (TP+FP)
# recall <- TP / (TP+FN)
# F1.score <- 2* precision * recall / (precision+recall)
# c(accuracy = accuracy, precision = precision, recall = recall,F1.score= F1.score)
```
